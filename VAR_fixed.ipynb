{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdata\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m      3\u001b[0m train, test \u001b[38;5;241m=\u001b[39m data[:train_size], data[train_size:]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Chuẩn hoá Max Min\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "# Chuẩn hoá Max Min\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(train)\n",
    "train_scaled = scaler.transform(train)\n",
    "train_scaled_df = pd.DataFrame(train_scaled, columns=data.columns, index=train.index)\n",
    "test_scaled = scaler.transform(test)\n",
    "test_scaled_df = pd.DataFrame(test_scaled, columns=data.columns, index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Dickey-Fuller Test: FDIGiaiNgan\n",
      "ADF Test Statistic      -2.941180\n",
      "p-value                  0.040765\n",
      "# Lags Used              9.000000\n",
      "# Observations Used     18.000000\n",
      "Critical Value (1%)     -3.859073\n",
      "Critical Value (5%)     -3.042046\n",
      "Critical Value (10%)    -2.660906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra tính dừng của các chuỗi (ADF test)\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(series, title=''):\n",
    "\n",
    "    print(f'Augmented Dickey-Fuller Test: {title}')\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    labels = ['ADF Test Statistic', 'p-value', '# Lags Used', '# Observations Used']\n",
    "    out = pd.Series(result[0:4], index=labels)\n",
    "    for key, value in result[4].items():\n",
    "        out[f'Critical Value ({key})'] = value\n",
    "    print(out.to_string())\n",
    "    print('')\n",
    "\n",
    "# Áp dụng ADF test cho từng đặc trưng\n",
    "adf_test(train['SoLuong'], title= 'SoLuong')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dùng tách mùa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Hàm tính toán các độ đo\n",
    "def calculate_metrics(true_values, forecast_values):\n",
    "    mse = np.mean((true_values - forecast_values) ** 2)  # Mean Squared Error\n",
    "    mae = np.mean(np.abs(true_values - forecast_values))  # Mean Absolute Error\n",
    "    rmse = np.sqrt(mse) \n",
    "    mape = np.mean(np.abs((true_values - forecast_values) / true_values)) * 100  # Mean Absolute Percentage Error\n",
    "    return mse, mae, rmse, mape\n",
    "\n",
    "def print_metrics(true_values, forecast_values):\n",
    "    mse, mae, rmse, mape = calculate_metrics(true_values, forecast_values)\n",
    "    print(f'MSE: {np.round(mse, 5)}, MAE: {np.round(mae, 5)}, RMSE: {np.round(rmse, 5)}, MAPE: {np.round(mape, 5)}')\n",
    "\n",
    "def forecast_var(data, forecast_steps ,max_lag ,Period):\n",
    "    # Tách mùa cho từng chuỗi dữ liệu\n",
    "    seasonal_decomposed = {}\n",
    "    for column in data.columns:\n",
    "        decomposition = seasonal_decompose(data[column], model='additive', period=Period)\n",
    "        seasonal_decomposed[column] = decomposition.seasonal\n",
    "\n",
    "    # Trừ phần mùa khỏi dữ liệu gốc để chỉ còn lại phần xu hướng và ngẫu nhiên\n",
    "    deseasonalized_data = data - pd.DataFrame(seasonal_decomposed)\n",
    "\n",
    "    # Chia tập train và tập test\n",
    "    train_size = int(len(deseasonalized_data) * 0.8)  # Sử dụng 80% dữ liệu làm tập train\n",
    "    train, test = deseasonalized_data.iloc[:train_size], deseasonalized_data.iloc[train_size:]\n",
    "\n",
    "    # Chuẩn hoá dữ liệu bằng Min-Max scaler chỉ trên tập huấn luyện\n",
    "    scaler = MinMaxScaler()\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    train_scaled_df = pd.DataFrame(train_scaled, columns=data.columns, index=train.index)\n",
    "    test_scaled = scaler.transform(test)\n",
    "    test_scaled_df = pd.DataFrame(test_scaled, columns=data.columns, index=test.index)\n",
    "\n",
    "    # Áp dụng sai phân\n",
    "    train_diff_df = train_scaled_df.diff().dropna()\n",
    "    test_diff_df = test_scaled_df.diff().dropna()\n",
    "\n",
    "    # Xây dựng mô hình VAR trên tập train\n",
    "    model = VAR(train_diff_df)\n",
    "\n",
    "    # Tìm ra số lượng lag tốt nhất\n",
    "    # best_lag = model.select_order()\n",
    "    # best_lag = best_lag.selected_orders['aic']\n",
    "\n",
    "    # Fit mô hình với số lượng lag tốt nhất trên tập train\n",
    "    result = model.fit(max_lag)\n",
    "\n",
    "    # Dự báo trên tập test\n",
    "    forecast = result.forecast(train_diff_df.values[-max_lag:], steps=len(test_diff_df))\n",
    "\n",
    "    # Chuyển kết quả dự báo về dạng DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast, columns=data.columns, index=test_diff_df.index)\n",
    "\n",
    "    # Đảo ngược quá trình sai phân để có kết quả dự báo thực tế\n",
    "    forecast_df = forecast_df.cumsum()\n",
    "    forecast_df = pd.DataFrame(scaler.inverse_transform(forecast_df), columns=data.columns, index=test_diff_df.index)\n",
    "\n",
    "    # Thêm lại phần mùa vào kết quả dự báo\n",
    "    seasonal_forecast = pd.DataFrame(seasonal_decomposed).iloc[train_size + 1:train_size + 1 + len(forecast_df)]\n",
    "    forecast_df += seasonal_forecast.values\n",
    "\n",
    "    # Cắt bỏ hàng cuối của tập test để phù hợp với độ dài của forecast_df\n",
    "    test = data[-forecast_steps:]\n",
    "    test_values = test.iloc[:, 0]\n",
    "    forecast = forecast_df[-forecast_steps:]\n",
    "    forecast_values = forecast.iloc[:, 0]\n",
    "    # print(forecast_values)\n",
    "    # print(test_values)\n",
    "\n",
    "    # Tính toán và in ra các độ đo\n",
    "    print_metrics(test_values, forecast_values.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trường hợp Var(1)\n",
      "MSE: 39684267834.89459, MAE: 147816.84333, RMSE: 199209.1058, MAPE: 38.66393\n",
      "Trường hợp Var(2)\n",
      "MSE: 58586182924.16897, MAE: 180668.17386, RMSE: 242045.82815, MAPE: 59.87996\n",
      "Trường hợp Var(3)\n",
      "MSE: 51936889624.3764, MAE: 194783.30903, RMSE: 227896.66436, MAPE: 66.66121\n",
      "Trường hợp Var(4)\n",
      "MSE: 35544295607.27241, MAE: 158413.35387, RMSE: 188531.94851, MAPE: 52.30694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\tensorFlow\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\User\\anaconda3\\envs\\tensorFlow\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\User\\anaconda3\\envs\\tensorFlow\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\User\\anaconda3\\envs\\tensorFlow\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('DL_TongHop.csv')  # Thay 'du_lieu.csv' bằng tên file của bạn\n",
    "# data = pd.read_excel('DL_Tonghop.xlsx')  # Thay 'du_lieu.csv' bằng tên file của bạn\n",
    "data.set_index('Thang', inplace=True)\n",
    "\n",
    "print(\"Trường hợp Var(1)\")\n",
    "data1 = data[['SoLuong','CPI','XuatKhau','NhapKhau','SxCongNghiep','FDIDangKy','FDIGiaiNgan','BanLe']]\n",
    "forecast_var(data1, forecast_steps = 6 ,max_lag = 1,Period = 12)\n",
    "\n",
    "print(\"Trường hợp Var(2)\")\n",
    "forecast_var(data1, forecast_steps = 6 ,max_lag = 2,Period = 12)\n",
    "\n",
    "print(\"Trường hợp Var(3)\")\n",
    "forecast_var(data1, forecast_steps = 6 ,max_lag = 3,Period = 12)\n",
    "\n",
    "print(\"Trường hợp Var(4)\")\n",
    "forecast_var(data1, forecast_steps = 6 ,max_lag = 4,Period = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trường hợp Var(1)\n",
      "MSE: 19583854052.2233, MAE: 125505.63738, RMSE: 139942.32402, MAPE: 32.58296\n",
      "Trường hợp Var(2)\n",
      "MSE: 13897577181.02504, MAE: 97202.47758, RMSE: 117887.98574, MAPE: 29.54838\n",
      "Trường hợp Var(3)\n",
      "MSE: 23309585576.47671, MAE: 138716.8125, RMSE: 152674.7706, MAPE: 38.93445\n",
      "Trường hợp Var(4)\n",
      "MSE: 14251882070.29255, MAE: 101764.93001, RMSE: 119381.24673, MAPE: 22.27879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\tensorFlow\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\User\\anaconda3\\envs\\tensorFlow\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\User\\anaconda3\\envs\\tensorFlow\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\User\\anaconda3\\envs\\tensorFlow\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('DL_TongHop.csv')  # Thay 'du_lieu.csv' bằng tên file của bạn\n",
    "# data = pd.read_excel('DL_Tonghop.xlsx')  # Thay 'du_lieu.csv' bằng tên file của bạn\n",
    "data.set_index('Thang', inplace=True)\n",
    "\n",
    "print(\"Trường hợp Var(1)\")\n",
    "data1 = data[['SoLuong','CPI','XuatKhau','NhapKhau','SxCongNghiep','FDIDangKy','FDIGiaiNgan','BanLe']]\n",
    "forecast_var(data1, forecast_steps = 3 ,max_lag = 1,Period = 12)\n",
    "\n",
    "print(\"Trường hợp Var(2)\")\n",
    "forecast_var(data1, forecast_steps = 3 ,max_lag = 2,Period = 12)\n",
    "\n",
    "print(\"Trường hợp Var(3)\")\n",
    "forecast_var(data1, forecast_steps = 3 ,max_lag = 3,Period = 12)\n",
    "\n",
    "print(\"Trường hợp Var(4)\")\n",
    "forecast_var(data1, forecast_steps = 3 ,max_lag = 4,Period = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dùng sai phân"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Hàm tính toán các độ đo\n",
    "def calculate_metrics(true_values, forecast_values):\n",
    "    mse = np.mean((true_values - forecast_values) ** 2)  # Mean Squared Error\n",
    "    mae = np.mean(np.abs(true_values - forecast_values))  # Mean Absolute Error\n",
    "    rmse = np.sqrt(mse) \n",
    "    mape = np.mean(np.abs((true_values - forecast_values) / true_values)) * 100  # Mean Absolute Percentage Error\n",
    "    return mse, mae, rmse, mape\n",
    "\n",
    "def print_metrics(true_values, forecast_values):\n",
    "    mse, mae, rmse, mape = calculate_metrics(true_values, forecast_values)\n",
    "    print(f'MSE: {np.round(mse)}, MAE: {np.round(mae)}, RMSE: {np.round(rmse)}, MAPE: {np.round(mape, 5)}%')\n",
    "\n",
    "def forecast_var(data, forecast_steps ,max_lag ,Period):\n",
    "    # Tách mùa cho từng chuỗi dữ liệu\n",
    "    seasonal_decomposed = {}\n",
    "    for column in data.columns:\n",
    "        decomposition = seasonal_decompose(data[column], model='additive', period=Period)\n",
    "        seasonal_decomposed[column] = decomposition.seasonal\n",
    "\n",
    "    # Trừ phần mùa khỏi dữ liệu gốc để chỉ còn lại phần xu hướng và ngẫu nhiên\n",
    "    deseasonalized_data = data - pd.DataFrame(seasonal_decomposed)\n",
    "\n",
    "    # Chia tập train và tập test\n",
    "    train_size = int(len(deseasonalized_data) * 0.8)  # Sử dụng 80% dữ liệu làm tập train\n",
    "    \n",
    "    train, test = deseasonalized_data.iloc[:train_size], deseasonalized_data.iloc[train_size:]\n",
    "    # print(test)\n",
    "\n",
    "    # Chuẩn hoá dữ liệu bằng Min-Max scaler chỉ trên tập huấn luyện\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    train_scaled_df = pd.DataFrame(train_scaled, columns=data.columns, index=train.index)\n",
    "    test_scaled = scaler.transform(test)\n",
    "    test_scaled_df = pd.DataFrame(test_scaled, columns=data.columns, index=test.index)\n",
    "\n",
    "    # # Áp dụng sai phân\n",
    "    # train_diff_df = train_scaled_df.diff().dropna()\n",
    "    # test_diff_df = test_scaled_df.diff().dropna()\n",
    "\n",
    "    # Xây dựng mô hình VAR trên tập train\n",
    "    model = VAR(train_scaled_df)\n",
    "\n",
    "    # Tìm ra số lượng lag tốt nhất\n",
    "    # best_lag = model.select_order()\n",
    "    # best_lag = best_lag.selected_orders['aic']\n",
    "\n",
    "    # Fit mô hình với số lượng lag tốt nhất trên tập train\n",
    "    result = model.fit(max_lag)\n",
    "\n",
    "    # Dự báo trên tập test\n",
    "    forecast = result.forecast(train_scaled_df.values[-max_lag:], steps=len(test_scaled_df))\n",
    "\n",
    "    # Chuyển kết quả dự báo về dạng DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast, columns=data.columns, index=test_scaled_df.index)\n",
    "\n",
    "    # Đảo ngược quá trình sai phân để có kết quả dự báo thực tế\n",
    "    \n",
    "    forecast_df = pd.DataFrame(scaler.inverse_transform(forecast_df), columns=data.columns, index=test_scaled_df.index)\n",
    "\n",
    "    # Thêm lại phần mùa vào kết quả dự báo\n",
    "    seasonal_forecast = pd.DataFrame(seasonal_decomposed).iloc[train_size:]\n",
    "    # print(seasonal_forecast.values)\n",
    "    # print(forecast_df)\n",
    "    forecast_df += seasonal_forecast.values\n",
    "\n",
    "    # Cắt bỏ hàng cuối của tập test để phù hợp với độ dài của forecast_df\n",
    "    test = data[-forecast_steps:]\n",
    "    test_values = test.iloc[:, 0]\n",
    "    forecast = forecast_df[-forecast_steps:]\n",
    "    forecast_values = forecast.iloc[:, 0]\n",
    "    # print(forecast_values)\n",
    "    # print(test_values)\n",
    "\n",
    "    # Tính toán và in ra các độ đo\n",
    "    print_metrics(test_values, forecast_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def calculate_metrics(true_values, forecast_values):\n",
    "    mse = np.mean((true_values - forecast_values) ** 2)  # Mean Squared Error\n",
    "    mae = np.mean(np.abs(true_values - forecast_values))  # Mean Absolute Error\n",
    "    rmse = np.sqrt(mse) \n",
    "    mape = np.mean(np.abs((true_values - forecast_values) / true_values)) * 100  # Mean Absolute Percentage Error\n",
    "    return mse, mae, rmse, mape\n",
    "\n",
    "def print_metrics(true_values, forecast_values):\n",
    "    mse, mae, rmse, mape = calculate_metrics(true_values, forecast_values)\n",
    "    print(f'MSE: {np.round(mse)}, MAE: {np.round(mae)}, RMSE: {np.round(rmse)}, MAPE: {np.round(mape, 5)}%')\n",
    "\n",
    "def forecast_ar(ar_series, forecast_steps, lag, period):\n",
    "    res_ar = sm.tsa.seasonal_decompose(ar_series, period=period, model='additive')\n",
    "    \n",
    "    # Deseasonalized data\n",
    "    deseasonalized_ar = ar_series - res_ar.seasonal\n",
    "    train_size = int(len(deseasonalized_ar) * 0.8)  # Sử dụng 80% dữ liệu làm tập train\n",
    "    \n",
    "    train, test = deseasonalized_ar.iloc[:train_size], deseasonalized_ar.iloc[train_size:]\n",
    "\n",
    "    # Chuẩn hoá dữ liệu bằng Min-Max scaler chỉ trên tập huấn luyện\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train.values.reshape(-1, 1))\n",
    "    train_scaled_df = pd.DataFrame(train_scaled, index=train.index)\n",
    "    test_scaled = scaler.transform(test.values.reshape(-1, 1))\n",
    "    test_scaled_df = pd.DataFrame(test_scaled, index=test.index)\n",
    "\n",
    "    # Step 2: Apply AR to the deseasonalized data\n",
    "    model = AutoReg(train_scaled_df.values.flatten(), lags=lag)\n",
    "    results = model.fit()\n",
    "\n",
    "    # Step 3: Forecast using AR model\n",
    "    forecast = results.predict(start=len(train_scaled_df), end=len(train_scaled_df) + len(test_scaled_df) - 1, dynamic=False)\n",
    "\n",
    "    # Chuyển kết quả dự báo về dạng DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast, index=test_scaled_df.index)\n",
    "\n",
    "    # Đảo ngược quá trình chuẩn hóa để có kết quả dự báo thực tế\n",
    "    forecast_df = pd.DataFrame(scaler.inverse_transform(forecast_df), index=test_scaled_df.index)\n",
    "\n",
    "    # Thêm lại phần mùa vào kết quả dự báo\n",
    "    forecast_df = forecast_df.squeeze() + res_ar.seasonal[train_size:]\n",
    "\n",
    "    # Cắt bỏ hàng cuối của tập test để phù hợp với độ dài của forecast_df\n",
    "    test = ar_series.iloc[train_size:]\n",
    "    test_values = test[-forecast_steps:]\n",
    "    forecast_values = forecast_df[-forecast_steps:]\n",
    "\n",
    "    # Tính toán và in ra các độ đo\n",
    "    print_metrics(test_values.values, forecast_values.values)\n",
    "\n",
    "# Example usage:\n",
    "# ar_series should be a pandas Series containing your time series data\n",
    "# forecast_steps is the number of steps you want to forecast\n",
    "# lag is the number of lag observations to use in the AR model\n",
    "# period is the period of seasonality\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'SoLuong' is the column with the time series data\n",
    "# forecast_ar(data['SoLuong'], forecast_steps=10, lag=5, period=12)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4886201316.0, MAE: 61817.0, RMSE: 69901.0, MAPE: 13.1599%\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('DL_TongHop.csv')  # Thay 'du_lieu.csv' bằng tên file của bạn\n",
    "# data = pd.read_excel('DL_Tonghop.xlsx')  # Thay 'du_lieu.csv' bằng tên file của bạn\n",
    "data.set_index('Thang', inplace=True)\n",
    "\n",
    "\n",
    "data1 = data['SoLuong']\n",
    "\n",
    "forecast_ar(data1, forecast_steps = 3 ,lag = 1,period = 12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
